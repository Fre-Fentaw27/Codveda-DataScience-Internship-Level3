# Codveda-DataScience-Internship-Level3

Time Series Analysis, Natural Language Processing (NLP)-Text Classification, Neural Networks with TensorFlow/Keras

## üìå Overview

This repository contains my solutions for the Level 2 Data Science Internship tasks, covering three fundamental machine learning areas: Regression, Classification, and Clustering. Each task demonstrates different aspects of data science workflow from data preprocessing to model evaluation.

## üìÇ Project Structure

```bash
Codveda-DataScience-Internship-Level3/
‚îÇ
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Sentiment dataset.csv                # Task 1: TimeSeries and Task 2: NLP Text Data
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ churn-bigml-80.csv                   # Task 3: Churn Training Data
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ churn-bigml-20.csv                   # Task 3: Churn Test Data
‚îÇ   ‚îî‚îÄ‚îÄ processed/
‚îÇ       ‚îú‚îÄ‚îÄ cleaned_sentiment.csv                # Task 1: Processed Data
‚îÇ       ‚îú‚îÄ‚îÄ cleaned_sentiment_task2.csv          # Task 2: Cleaned Text Data
‚îÇ       ‚îú‚îÄ‚îÄ features/
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ tfidf_features.pkl               # Task 2: TF-IDF Features
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ tfidf_vectorizer.pkl             # Task 2: TF-IDF Vectorizer
‚îÇ       ‚îî‚îÄ‚îÄ churn_processed.pkl                  # Task 3: Processed Churn Data
‚îÇ
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ Task1_TimeSeries/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ data_processing.py                   # Time Series Data Processing
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ time_series_analysis.ipynb           # Time Series Analysis and Forecasting Models
‚îÇ   ‚îú‚îÄ‚îÄ Task2_NLP/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ nlp_exploration
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ nlp_data_processing.py               # Text Preprocessing
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ nlp_feature_extraction.py            # TF-IDF Feature Extraction
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ nlp_model_training.py                # Model Training
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ nlp_evaluation.py                    # Model Evaluation
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ predict_sentiment.py                 # Sentiment Prediction
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ Task3_NeuralNetworks/
‚îÇ       ‚îú‚îÄ‚îÄ churn_data_processing.py             # Churn Data Processing
‚îÇ       ‚îú‚îÄ‚îÄ churn_nn_model.py                    # Neural Network Model
‚îÇ       ‚îú‚îÄ‚îÄ churn_hyperparameter_tuning.py       # Hyperparameter Tuning
‚îÇ       ‚îú‚îÄ‚îÄ churn_evaluation.py                  # Model Evaluation
‚îÇ       ‚îî‚îÄ‚îÄ churn_pipeline.py                    # Complete Churn Pipeline
‚îÇ
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ Task1_TimeSeries/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ arima_model.pkl                      # ARIMA Model
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ sarima_model.pkl                     # SARIMA Model
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ prophet_model.pkl                    # Prophet Model
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ Task2_NLP/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ best_model.pkl                       # Best NLP Model
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ model_comparison_results.csv         # Model Comparison
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ model_info.pkl                       # Model Information
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ Task3_NeuralNetworks/
‚îÇ       ‚îú‚îÄ‚îÄ best_churn_model.h5                  # Best Neural Network
‚îÇ       ‚îú‚îÄ‚îÄ model_architecture.png               # Model Architecture
‚îÇ       ‚îî‚îÄ‚îÄ training_history/                    # Training History Files
‚îÇ
‚îú‚îÄ‚îÄ outputs/
‚îÇ   ‚îú‚îÄ‚îÄ Task1_TimeSeries/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ decomposition_plot.png               # Time Series Decomposition
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ forecast_results.png                 # Forecast Visualization
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ acf_pacf_plots.png                   # ACF/PACF Analysis
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ model_evaluation.txt                 # Evaluation Metrics
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ Task2_NLP/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ class_distribution.png               # Sentiment Distribution
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ confusion_matrix.png                 # Confusion Matrix
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ feature_importance.png               # Feature Importance
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ model_performance.png                # Model Comparison
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ classification_report.txt            # Detailed Report
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ results_summary.txt                  # Results Summary
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ Task3_NeuralNetworks/
‚îÇ       ‚îú‚îÄ‚îÄ accuracy_curve.png                   # Accuracy Curve
‚îÇ       ‚îú‚îÄ‚îÄ loss_curve.png                       # Loss Curve
‚îÇ       ‚îú‚îÄ‚îÄ confusion_matrix.png                 # Confusion Matrix
‚îÇ       ‚îú‚îÄ‚îÄ feature_importance.png               # Feature Importance
‚îÇ       ‚îú‚îÄ‚îÄ churn_distribution.png               # Churn Distribution
‚îÇ       ‚îú‚îÄ‚îÄ correlation_heatmap.png              # Correlation Heatmap
‚îÇ       ‚îî‚îÄ‚îÄ model_performance.txt                # Performance Metrics
‚îÇ
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îú‚îÄ‚îÄ Task1_TimeSeries/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ time_series_analysis.ipynb           # Time Series Exploration
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ Task2_NLP/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ nlp_exploration.ipynb                # NLP Data Exploration
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ nlp_model_analysis.ipynb             # Model Analysis
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ Task3_NeuralNetworks/
‚îÇ       ‚îî‚îÄ‚îÄ churn_analysis.ipynb                 # Churn Data Analysis
‚îÇ
‚îú‚îÄ‚îÄ requirements.txt                             # Python Dependencies
‚îú‚îÄ‚îÄ .gitignore                                   # Git Ignore File
‚îî‚îÄ‚îÄ README.md                                    # Project Documentation
```

## üöÄ Project Tasks

## Task 1: Time Series Analysis

**Description**: Analyze and model time-series data to forecast future values

**Objectives Achieved**:

‚úÖ Decompose time series into trend, seasonality, and residuals

‚úÖ Implement ARIMA, SARIMA, and Prophet models

‚úÖ Evaluate models using MAE, RMSE, and MAPE

**Key Results**: Random Forest achieved the best performance with R¬≤ = 0.85

## Task 2: Natural Language Processing (NLP) - Text Classification

**Description**: Classify text data into sentiment categories
**Objectives Achieved**:

‚úÖ Preprocess text data (tokenization, stopwords removal, lemmatization)

‚úÖ Convert text to numerical representation using TF-IDF

‚úÖ Train classification models (Naive Bayes, Logistic Regression, SVM, Random Forest)

‚úÖ Evaluate using precision, recall, and F1-score

- **Key Results**: All models achieved >95% accuracy, with Random Forest performing best

## Task 3: Neural Networks with TensorFlow/Keras

- **Description**: Build and train neural network for churn prediction

- **Objectives Achieved**:

‚úÖ Preprocess structured churn prediction data

‚úÖ Design neural network architecture

‚úÖ Train model using backpropagation

‚úÖ Tune hyperparameters (learning rate, batch size)

‚úÖ Evaluate using accuracy and loss curves

- **Key Results**: Identified 9 distinct customer segments with unique characteristics

## üõ†Ô∏è Setup & Installation

1.  **Clone the repository** (if applicable) or ensure you have the project structure locally.
2.  **Navigate to the project root directory** in your terminal.
3.  **Create a virtual environment** (recommended):
    ```bash
    python -m venv .venv
    ```
4.  **Activate the virtual environment**:
    - On Windows:
      ```bash
      .venv\Scripts\activate
      ```
    - On macOS/Linux:
      ```bash
      source .venv/bin/activate
      ```
5.  **Install dependencies**:

    ```bash
    pip install -r requirements.txt
    ```

## üìä Usage

1. Task 1: Time Series Analysis:

```bash
python src/Task1_TimeSeries/data_processing.py
```

```bash
python src/Task1_TimeSeries/time_series_analysis.ipynb
```

2. Task 2: Natural Language Processing (NLP) - Text Classification

```bash
cd src/Task2_NLP/
# run individually:
python nlp_data_processing.py
python nlp_feature_extraction.py
python nlp_model_training.py
python nlp_evaluation.py
```

3. Task 3: Neural Networks with TensorFlow/Keras:

```bash
cd src/Task3_NeuralNetworks/
# run individually:
python churn_data_processing.py
python churn_nn_model.py
```

## Exploring Results

**Visualizations**: Check results/task\_\*/ for all generated plots

**Processed Data**: Available in data/processed/

**Trained Models**: Stored in models/task\_\*/

## üîß Technologies Used

**Data Processing**: pandas, numpy

**Visualization**: matplotlib, seaborn, plotly

**Machine Learning**: scikit-learn, xgboost

**Model Serialization**: joblib

**Notebooks**: Jupyter
